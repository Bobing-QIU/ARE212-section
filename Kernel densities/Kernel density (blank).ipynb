{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23a413b4",
   "metadata": {},
   "source": [
    "# Kernel density estimators\n",
    "\n",
    "The concepts that this notebook will illustrate are:\n",
    "* Writing kernel density functions\n",
    "* Using list comprehensions to generate data\n",
    "* Using lambda functions to pass functions to other functions\n",
    "* Basic plotting\n",
    "\n",
    "## The problem\n",
    "\n",
    "Sometimes in research, your goal might be to approximate the distribution of the data you have. This can be because you are doing some kind of prediction exercise where you want to be able to reproduce the data from some set of covariates, or simply because you want to summarise the distribution in a graph in a sensible way. But given a set of data points, which are inherently discrete, how to smooth these into an approximation of a density?\n",
    "\n",
    "For example, consider you get a dataset with 50 points. Because we are creating this dataset here we know what distribution these data come from, but you wouldn't know that as a researcher just receiving the data points. Let's make some weird data and take a look.\n",
    "\n",
    "**First** you will need to install the following packages via conda if you dont have them already. In terminal:\n",
    "```\n",
    "conda activate are212\n",
    "conda install -c conda-forge matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27fe63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import distributions as iid\n",
    "from numpy import random\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create the true density with a (strange) density\n",
    "def our_pdf(N):\n",
    "    # distribution support \n",
    "    a = 0\n",
    "    b = 2*np.pi\n",
    "    x = np.linspace(a, b, N)\n",
    "    \n",
    "    return {'pdf' : (np.sin(x*6*2*np.pi/(a-b)) + 1)/(b - a), 'x' : x}\n",
    "\n",
    "# method for noisy sampling\n",
    "def sample(N, pdf=our_pdf):\n",
    "    # create large data -> approximates true distribution\n",
    "    large_data_x, large_data_p = our_pdf(10000)['x'], our_pdf(10000)['pdf']\n",
    "    # sample from this using discretized probabilities\n",
    "    sample = random.choice(large_data_x, p=large_data_p/large_data_p.sum(), size=(N))\n",
    "    return sample    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Visualize the distribution \n",
    "\n",
    "# the true distribution is produced with large enough N\n",
    "true_distrib = our_pdf(10000)\n",
    "X = sample(100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(true_distrib['x'], true_distrib['pdf'], label='True pdf function')\n",
    "ax.hist(X, density=True, bins=int(np.sqrt(100)), label='Sample density')\n",
    "\n",
    "ax.set(xlabel='X Values', ylabel='Count',title=\"True PDF of X against sample histogram\")\n",
    "plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a947a5",
   "metadata": {},
   "source": [
    "## A solution\n",
    "\n",
    "Above we can get some sense of the distribution with a histogram, but this is not totally satisfying since the histogram is literally chunky- it is a set of rectangles, whereas these sharp edges don't actually exist in our data. So what is another way to approximate the distribution? Kernel densities. \n",
    "\n",
    "### Some math\n",
    "\n",
    "Now that we know that the goal of a kernel density is to approximate a PDF, let's do some math. We know that a PDF ($f$) is the derivative of a CDF ($F$). We don't actually know the CDF, but we can use the empirical distirbution to define:\n",
    "\n",
    "$$\\widehat{F}(x) = \\frac{1}{n}\\sum_i 1(X_i \\leq x)$$\n",
    "\n",
    "**Check your understanding:** Why doesn't this kind of approximation work to create $\\hat{f}(x) = P(X_i = x)$?\n",
    "\n",
    "With this, using the definition of a derivative, let:\n",
    "\\begin{align*}\n",
    "\\hat{f}(x) &= \\frac{\\widehat{F}(x+h) - \\widehat{F}(x-h)}{2h} \\\\\n",
    "&= \\frac{1}{2h} \\sum_i \\frac{1(X_i \\leq x+h)}{n} - \\frac{1(X_i \\leq x-h)}{n} \\\\\n",
    "&= \\frac{1}{2h} \\sum_i \\frac{1(x-h\\leq X_i \\leq x+h)}{n} \\\\\n",
    "&= \\frac{1}{2hn} \\sum_i 1(-1\\leq \\frac{X_i - x}{h} \\leq 1) \\\\\n",
    "&= \\frac{1}{2hn} \\sum_i 1(\\frac{|X_i - x|}{h} \\leq 1) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Calling the $1()$ function $k(u) = 1/2$ if $u\\leq 1$, where $u = \\frac{1}{h}(X_i-x)$, we have a kernel density. But we don't have to limit $k()$ to be an indicator function. We can use any function that is:\n",
    "1. Non-negative\n",
    "2. Bounded\n",
    "3. Symmetric\n",
    "4. Differentiable\n",
    "\n",
    "For example, these are all kernel densities (the last one is Cauchy, from the kernel density exercises):\n",
    "\n",
    "\\begin{align}\n",
    "K_1(u) &= \\begin{cases}\n",
    "1/2 & |u| < 1 \\\\ \n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} \\\\ \n",
    "K_2(u) &= \\begin{cases}\n",
    "\\frac{1-|u|}{2} & |u| < 1 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} \\\\ \n",
    "K_3(u) &= \\begin{cases}\n",
    "\\frac{3}{4\\sqrt{5}}(1-\\frac{u^2}{5}) & |u| < \\sqrt{5} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Let's program a simulation that takes each of these kernel densities and plots it against the true (oracle) density.\n",
    "\n",
    "One trick that will help us with these indicator functions is that the boolean ``True`` in python evaluates to 1. So we can multiply our expressions by a boolean that checks if the conditional is satisfied to push everything else outside to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum([True, False, True]))\n",
    "print(f\"(1 < 2)*1 = {(1 < 2)*1}\")\n",
    "print(f\"(1 > 2)*1 = {(1 > 2)*1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define kernel densities. First, see that these 3 options for K_1 are all equivalent\n",
    "def K1(u):\n",
    "    return 0.5*(np.abs(u) < 1)\n",
    "\n",
    "def K1_1(u):\n",
    "    if np.abs(u) < 1:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "K1_2 = lambda u: 0.5*(np.abs(u) < 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01924e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" K1(0)   = {K1(0)}\\n K1_1(0) = {K1_1(0)}\\n K1_2(0) = {K1_2(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf93746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K2(u):\n",
    "    return None\n",
    "\n",
    "def K3(u):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3aadf0",
   "metadata": {},
   "source": [
    "Now let's make a dictionary of kernel functions that we will later loop over to estimate the kernel density function at each point in x. These functions will be a function of $u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ca3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = {\"Uniform\" : K1,\n",
    "           \"Linear\"  : K2,\n",
    "           \"Cauchy\"  : K3\n",
    "          }\n",
    "\n",
    "# test: kernels['Linear'] returns a function that we can then call\n",
    "kernels['Linear'](0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50bf902",
   "metadata": {},
   "source": [
    "Now for each kernel, we want to estimate it at each point in the data. Let's also loop over a few bandwidths just for fun. We'll do 2 bandwidths, which plus the 3 kernels implies 6 total plots. The idea is:\n",
    "\n",
    "```\n",
    "for each bandwidth and each kernel:\n",
    "    calculate f_hat(x) = (1/nh) \\sum_i k((x_i - x)/h) for each x in the data\n",
    "```\n",
    "\n",
    "For readability, let's write f_hat as a function first. ``f_hat()`` needs to know:\n",
    "* The kernel function k()\n",
    "* h\n",
    "* x\n",
    "* The data X\n",
    "\n",
    "**Aside:** The ``apply()`` method of ``pd.Series()``\n",
    "\n",
    "The ``pandas`` (usually imported as ``pd``) package is the main data organizer in python, and has a ton of really great functions. The main data types in pandas are:\n",
    "* ``pd.Series``\n",
    "* ``pd.DataFrame``, where eachs column is a ``pd.Series``. \n",
    "\n",
    "You can subset pandas dataframe columns by calling ``df['colname']`` or ``df.colname``, which will then return a pandas Series. Series can have lots of different operations done to them, and when you have a custom operation you can use the ``apply`` method of ``pd.Series`` to apply the function to each entry in the column. Calling apply works like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5e0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.Series([1,2,3,4], name='test')\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e24602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evenOrOdd(x, oppositeDay=False):\n",
    "    if (x % 2 == 0 and not oppositeDay) or (x % 2 == 1 and oppositeDay):\n",
    "        return \"Even\"\n",
    "    if (x % 2 == 0 and oppositeDay) or (x % 2 == 1 and not oppositeDay):\n",
    "        return \"Odd\"\n",
    "\n",
    "# when just a function of one variable, can call function name directly\n",
    "X_test.apply(evenOrOdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ea29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when a function of > 1 var, use lambda functions to mask the other ones\n",
    "X_test.apply(lambda x: evenOrOdd(x, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e82f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_hat(x, X, h, k):\n",
    "    '''\n",
    "    x: double, A point to evaluate f_hat at\n",
    "    X: pd.Series, an array of data points\n",
    "    h: double, bandwidth\n",
    "    k: function, the kernel density function\n",
    "    \n",
    "    Returns: double, 1/(nh) \\sum_i k((x_i - x)/h)\n",
    "    '''\n",
    "    n = len(X)\n",
    "    \n",
    "    # apply kernel function to each element of X\n",
    "    k_h = X.apply(lambda x_i: k((x_i - x)/h))\n",
    "    \n",
    "    return None\n",
    "\n",
    "# test\n",
    "f_hat(0, pd.Series(X), 5, kernels[\"Linear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize figure space\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15,7))\n",
    "# sort X so we move across the axis\n",
    "X = pd.Series(X).sort_values()\n",
    "\n",
    "# counter is for axis positioning\n",
    "counter = 0\n",
    "\n",
    "for h in [.1, 2]: # loop over bandwidths\n",
    "    for name, k in kernels.items(): # loop over kernel names, functions\n",
    "        # row moves to 1 after 3rd iteration\n",
    "        if counter < 3:\n",
    "            row = 0\n",
    "        else:\n",
    "            row = 1\n",
    "        # calculate fhat for each x, plot against x\n",
    "        ax[row, counter % 3].plot(X, X.apply(lambda x_i: f_hat(x_i, X, h, k)))\n",
    "        # label \n",
    "        ax[row, counter % 3].set_title(f'h = {h}, k = {name}')\n",
    "        # move counter forward\n",
    "        counter += 1\n",
    "      \n",
    "fig.suptitle(\"Estimated PDF with different kernels, bandwidths\", size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
