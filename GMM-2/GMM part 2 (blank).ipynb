{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615adce1",
   "metadata": {},
   "source": [
    "# GMM, round 2\n",
    "\n",
    "We've seen the basics of how 2-step GMM works; now we are going to organize our code using the ``class`` and ``module`` structures in python, and walk through another example involving testing model fit. First, organization.\n",
    "\n",
    "## Organizing code into classes and modules\n",
    "As we've seen with GMM, there are a lot of \"little\" functions that help us estimate: ``gj``, ``gN``, ``minimize``... A nice way to make our code more concise and readable is to collect these functions into a python **module**. Modules are just ``.py`` scripts that contain functions, and sometimes even classes. They also import the libraries that these functions depend on. This is what ``gmm.py`` is in Ethan's repository (reproduced in this folder).\n",
    "\n",
    "Let's take a look...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now that we have all the building blocks set up, we can systematize calling them by organizing them into a class. First, we need to set up instantiation. Here are some coding tricks that will come in handy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trick 1: try\n",
    "# Let's say I have a function that receives an input x,\n",
    "# but it doesnt know if x is a number or a list.\n",
    "# This is like our betas; there may be just 1 (a number)\n",
    "# or L (a list)\n",
    "# try let's us try to code something, and then tell python \n",
    "# what to do if that fails\n",
    "x = 2\n",
    "y = [1, 2, 3]\n",
    "\n",
    "def demonstrateTry(z):\n",
    "    try:\n",
    "        print(f\"z has len {len(z)}\") \n",
    "        # try to print the length of x, \n",
    "        # which will only work if a list\n",
    "    except:\n",
    "        print(\"z is a scalar\")\n",
    "    # here I do this given any error above, but I can be \n",
    "    # more specific about what to do for a given type of error.\n",
    "    # like: except TypeError:\n",
    "    \n",
    "demonstrateTry(x)\n",
    "demonstrateTry(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f3c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    len(x)\n",
    "except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086aa2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trick 2: Another way to plan for different types of variables\n",
    "# being passed is to do if statements. Let's say we don't know if\n",
    "# x is a tuple of data, like (y, X, Z), or just a matrix like X.\n",
    "import numpy as np\n",
    "\n",
    "def testType(data):\n",
    "    if type(data) is tuple:\n",
    "        X = data[1]\n",
    "    else:\n",
    "        X = data\n",
    "    # print the shape to see that we get back something\n",
    "    # that makes sense\n",
    "    print(X.shape)\n",
    "\n",
    "# make some random data\n",
    "randomNormal = lambda K: np.random.normal(size = (10, K))    \n",
    "data1 = (randomNormal(1), randomNormal(2), randomNormal(2)) # tuple\n",
    "data2 = randomNormal(2) # numpy array\n",
    "\n",
    "# test\n",
    "testType(data1)\n",
    "testType(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b67ad6",
   "metadata": {},
   "source": [
    "First let's look at just the instantiation, that is, the setting of attributes and what gets passed in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca588c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmm\n",
    "import numpy as np\n",
    "\n",
    "class GMM: # not necessary to inherit from object as Ethan does\n",
    "    # Constructor\n",
    "    def __init__(self,gj,data,B,W=None):\n",
    "        \"\"\"GMM problem for restrictions E(gj(b0))=0, \n",
    "        estimated using data with b0 in R^k.\n",
    "\n",
    "           - If supplied B is a positive integer k, then \n",
    "             space taken to be R^k.  \n",
    "           - If supplied B is a k-vector, then\n",
    "             parameter space taken to be R^k with B a possible\n",
    "             starting value for optimization.\n",
    "        \"\"\"\n",
    "        # set attribute\n",
    "        self.gj = gj\n",
    "        # Overwrite member of gmm module by passing our FUNCTION gj \n",
    "        # all the way back to the gmm module\n",
    "        gmm.gj = gj  \n",
    "        # set attribute\n",
    "        self.data = data\n",
    "        # set attribute\n",
    "        self.W = W\n",
    "        # set attribute b to None since we haven't solved for this yet\n",
    "        self.b = None\n",
    "        # set attributes based on B\n",
    "        try:\n",
    "            self.k = len(B)\n",
    "            self.b_init = np.array(B)\n",
    "        except TypeError:\n",
    "            self.k = B\n",
    "            self.b_init = np.zeros(self.k)\n",
    "        # infer the number of moment conditions L (ell)\n",
    "        # from the no. of columns of g_j\n",
    "        self.ell = gj(self.b_init,self.data).shape[1]\n",
    "        # infer the no. of obs from the no. of rows in the data\n",
    "        # if the data is a tuple (like (y, X, Z)), then we first\n",
    "        # need to subset the tuple then get the shape\n",
    "        if type(data) is tuple:\n",
    "            self.N = data[0].shape[0]\n",
    "        else:\n",
    "            self.N = data.shape[0]\n",
    "        # set the minimizer function \n",
    "        self.minimize = gmm.minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c86e17",
   "metadata": {},
   "source": [
    "Now let's add in our methods, which we can conveniently inherit from the GMM module!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc805ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "\n",
    "    def __init__(self,gj,data,B,W=None):\n",
    "        \"\"\"GMM problem for restrictions E(gj(b0))=0, \n",
    "        estimated using data with b0 in R^k.\n",
    "\n",
    "           - If supplied B is a positive integer k, then \n",
    "             space taken to be R^k.  \n",
    "           - If supplied B is a k-vector, then\n",
    "             parameter space taken to be R^k with B a possible\n",
    "             starting value for optimization.\n",
    "        \"\"\"\n",
    "        self.gj = gj\n",
    "        gmm.gj = gj  # Overwrite member of gmm module\n",
    "        self.data = data\n",
    "\n",
    "        self.W = W\n",
    "\n",
    "        self.b = None\n",
    "\n",
    "        try:\n",
    "            self.k = len(B)\n",
    "            self.b_init = np.array(B)\n",
    "        except TypeError:\n",
    "            self.k = B\n",
    "            self.b_init = np.zeros(self.k)\n",
    "\n",
    "        self.ell = gj(self.b_init,self.data).shape[1]\n",
    "\n",
    "        if type(data) is tuple:\n",
    "            self.N = data[0].shape[0]\n",
    "        else:\n",
    "            self.N = data.shape[0]\n",
    "\n",
    "        self.minimize = gmm.minimize\n",
    "            \n",
    "    def gN(self,b):\n",
    "        \"\"\"Averages of g_j(b).\n",
    "        This is generic for data, to be passed to gj.\n",
    "        \"\"\"\n",
    "        return gmm.gN(b,self.data)\n",
    "\n",
    "    def Omegahat(self,b):\n",
    "        return gmm.Omegahat(b,self.data)\n",
    "    \n",
    "    def J(self,b,W):\n",
    "        return gmm.J(b,W,self.data)\n",
    "\n",
    "    def one_step_gmm(self,W=None,b_init=None):\n",
    "        self.b = gmm.one_step_gmm(self.data,W,b_init=self.b_init)\n",
    "        return self.b\n",
    "    \n",
    "    def two_step_gmm(self):\n",
    "        self.b = gmm.two_step_gmm(self.data,b_init=self.b_init)[0]\n",
    "        return self.b\n",
    "\n",
    "    def continuously_updated_gmm(self):\n",
    "        self.b = gmm.continuously_updated_gmm(self.data,b_init=self.b_init)[0]\n",
    "        return self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf66c868",
   "metadata": {},
   "source": [
    "## Another example of a GMM application\n",
    "\n",
    "Remember: GMM starts with a _hypothesis_; we assert a moment condition that we believe to hold because of logic, a model, etc., and then use data to back out the parameters that best help the data match this assertion.\n",
    "\n",
    "In IV, our assertion is that the instrument is not correlated with the error. That is, we have reason to believe (because of a model, logic, whatever) that Z only affects Y through X, so we assert this through the moment condition $E(Z'e) = E(Z'(y - X\\beta)) = 0$, and solve for the $\\beta_k$ that most closely make this assertion hold in the data. Similarly, in our last section, we asserted the first order conditions that \"believed\" should hold, then solved for the $\\alpha$ that best made the data match. \n",
    "\n",
    "Here we will propose a new model we want to estimate with GMM, but this time we will make 2 data generating processes: one where the true relationship does hold in the data, and one where it absolutely does not, and see how GMM behaves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14211e0d",
   "metadata": {},
   "source": [
    "### Model set-up\n",
    "\n",
    "Consider a non-linear, commonly called Poisson ML process:\n",
    "\n",
    "$$y_i = exp\\{X_i\\beta\\} + e_i$$\n",
    "\n",
    "We may posit this relationship primarily if we think that the error enters separately from the exponential for some reason. Alternatively, this is an attractive approximation if we believe there is a relationship between log y and $X_i\\beta$, and in particular there are some (or a lot) of zeros in y preventing us from taking logs (environment friends: the inverse hyperbolic sine function is [not always your friend](https://marcfbellemare.com/wordpress/wp-content/uploads/2019/02/BellemareWichmanIHSFebruary2019.pdf)).\n",
    "\n",
    "Suppose we have an instrument for $X_i$, but we already know from the forbidden regression that we cannot apply IV when the second stage is non-linear! Welcome, GMM.\n",
    "\n",
    "To be clear, the exogeneity of Z is _our assertion_. That is, we as the researcher have reason to believe that:\n",
    "\n",
    "$$E(e_i | z_i) = 0 \\Rightarrow E(z_i'e_i) = 0$$\n",
    "\n",
    "So we use this \"information\" to propose our moment condition:\n",
    "\n",
    "$$g_j(\\beta) = E(z_i'e_i) = E(z_i'(y_i - exp\\{X_i\\beta\\})) = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d74c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gj(b, data):\n",
    "    # make sure b is the right shape\n",
    "    b = b.reshape(2,1)\n",
    "    \n",
    "    y, X, Z = data\n",
    "    Z_0 = Z[:, [0]]\n",
    "    Z_1 = Z[:, [1]]\n",
    "    Z_2 = Z[:, [2]]\n",
    "\n",
    "    e = y - np.exp(X@b)\n",
    "    #horizontally stack the instruments for an\n",
    "    #Nx2 matrix\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a31b1",
   "metadata": {},
   "source": [
    "Now we want 2 data-generating processes: one where our instrument is exogenous, and one where exogeneity is violated. To do this, I define a single DGP function, which takes as a parameter the covariance between Z and e, which should be 0 in the exogenous case, and $\\neq 0$ in the case of endogeneity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a125b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as iid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4153d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgp(N, true_beta, cov_ze=0):\n",
    "    # define covariance mat of XEZ:\n",
    "    cov_XEZZ = np.array(\n",
    "        [[4, 1, 1, 2],\n",
    "        [1, 2, cov_ze, cov_ze*0.5],\n",
    "        [1, cov_ze, 3, 0.2],\n",
    "        [2, cov_ze*.5, 0.2, 8]])*0.1\n",
    "    \n",
    "    XEZZ = iid.multivariate_normal(mean=[.2, 0, 0, 0],\n",
    "                                   cov=cov_XEZZ).rvs(size = N)\n",
    "    \n",
    "    X = XEZZ[:, [0]]\n",
    "    \n",
    "    e = XEZZ[:, [1]]\n",
    "    \n",
    "    Z = XEZZ[:, 2:]\n",
    "    \n",
    "    y = ...\n",
    "    X = np.c_[np.ones(shape = (N,1)), X] # add intercept\n",
    "    Z = np.c_[np.ones(shape = (N,1)), Z]\n",
    "    \n",
    "    return (y, X, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abfc215",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_beta = np.array([.2, .1])\n",
    "N = 10000\n",
    "\n",
    "# exogenous DGP\n",
    "data_exog = dgp(N, true_beta)\n",
    "# endogenous DGP\n",
    "data_endog = dgp(N, true_beta, cov_ze = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf203c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test IV estimate under exogeneity: true_beta = .1\n",
    "from numpy.linalg import pinv\n",
    "\n",
    "print(pinv(data_exog[2].T@(data_exog[1]))@\n",
    "      (data_exog[2].T)@(data_exog[0]))\n",
    "\n",
    "# Note this is close (except the intercept)!\n",
    "# but the SEs are going to be all wrong!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test IV estimate when Z is endogenous: true_beta = .1\n",
    "print(pinv(data_endog[2].T@(data_endog[1]))@\n",
    "      (data_endog[2].T)@(data_endog[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2455af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at our moment conditions\n",
    "gj(true_beta, data_exog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d64d7f",
   "metadata": {},
   "source": [
    "So far we have a DGP capable of making data for which our IV moment condition is satisfied and for which it is not. Let's see how GMM performs for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c3059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. instantiate\n",
    "b0 = np.array([[0,0]]).T\n",
    "\n",
    "gmm_endog = GMM(gj,data_endog,b0)\n",
    "gmm_exog = GMM(gj,data_exog,b0)\n",
    "\n",
    "# 2. estimate\n",
    "print(f\"true beta = {true_beta}\")\n",
    "print(f\"beta estimate for endog. DGP: {gmm_endog.two_step_gmm()}\")\n",
    "print(f\"beta estimate for exog. DGP: {gmm_exog.two_step_gmm()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e49a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should we accept these models?\n",
    "J_crit = limiting_J = iid.chi2(3-1).isf(0.05)\n",
    "\n",
    "J_exog = ...\n",
    "J_endog = ...\n",
    "\n",
    "\n",
    "print(f\"Critical stat for rejecting null of J: {J_crit:.4f}\")\n",
    "print(f\"J_stat_endog = {J_endog:.4f}, J_stat_exog = {J_exog:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
